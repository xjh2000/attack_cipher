{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env\n",
    "\n",
    "test the env for the torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1517, 0.1385, 0.3776],\n",
      "        [0.3969, 0.8731, 0.6285],\n",
      "        [0.5430, 0.5114, 0.8157],\n",
      "        [0.4969, 0.2510, 0.8303],\n",
      "        [0.5157, 0.3710, 0.7567]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "# if torch.cuda.is_available():\n",
    "#     print(\"CUDA is available!\")\n",
    "#     device = torch.device(\"cuda\")\n",
    "# else:\n",
    "#     print(\"CUDA is not available.\")\n",
    "#     device = torch.device(\"cpu\")\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "# Create a tensor\n",
    "x = torch.rand(5, 3)\n",
    "\n",
    "# Move the tensor to the GPU\n",
    "x = x.to(device)\n",
    "\n",
    "# Print the tensor\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create the dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from Crypto.Cipher import DES\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DESDataset(Dataset):\n",
    "    def __init__(self, num_samples):\n",
    "        self.num_samples = num_samples\n",
    "        self.key = 0x12345678.to_bytes(8, byteorder=\"big\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        des = DES.new(self.key, DES.MODE_ECB)  # Initialize DES cipher with a key\n",
    "        plaintext = np.random.bytes(8)  # Generate a random 64-bit plaintext\n",
    "        ciphertext = des.encrypt(plaintext)  # Encrypt the plaintext\n",
    "        # Convert ciphertext to binary string\n",
    "        ciphertext_bin = \"\".join(format(byte, \"08b\") for byte in ciphertext)\n",
    "        # Convert each bit to a uint8 and store in a numpy array\n",
    "        ciphertext_bits = np.array([np.uint8(bit) for bit in ciphertext_bin])\n",
    "\n",
    "        label = (plaintext[0] & 0x80) >> 7  # Get the first bit of the plaintext\n",
    "\n",
    "        ciphertext_tensor = (\n",
    "            torch.from_numpy(np.copy(ciphertext_bits)).float().to(device)\n",
    "        )\n",
    "\n",
    "        label_tensor = torch.tensor(label, dtype=torch.int64).float().to(device)\n",
    "        return (ciphertext_tensor, label_tensor)\n",
    "\n",
    "\n",
    "# if have .pth file, load it or create a new one\n",
    "# try:\n",
    "#     dataset = torch.load(\"data/des_dataset.pth\")\n",
    "#     print(\"Dataset loaded from data/des_dataset.pth\")\n",
    "# except FileNotFoundError:\n",
    "#     print(\"Creating a new dataset\")\n",
    "#     dataset = DESDataset(10000)\n",
    "#     torch.save(dataset, \"data/des_dataset.pth\")\n",
    "\n",
    "dataset = DESDataset(100000)\n",
    "ciphertext, lable = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, test_size]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            1, 16, 3, padding=1\n",
    "        )  # Convolutional layer (16 channels, kernel size 3)\n",
    "        self.pool = nn.MaxPool1d(2)  # Max pooling layer (pool size 2)\n",
    "        self.fc1 = nn.Linear(32 * 16, 64)  # Fully connected layer (64 units)\n",
    "        self.fc2 = nn.Linear(64, 1)  # Output layer (1 unit)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add a channel dimension\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Convolutional layer + ReLU + pooling\n",
    "        x = x.view(-1, 16 * 32)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))  # Fully connected layer + ReLU\n",
    "        x = torch.sigmoid(self.fc2(x))  # Output layer + sigmoid activation\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize the CNN\n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 132.885\n",
      "[1,  1000] loss: 132.973\n",
      "[2,   500] loss: 134.136\n",
      "[2,  1000] loss: 133.103\n",
      "[3,   500] loss: 132.553\n",
      "[3,  1000] loss: 132.653\n",
      "[4,   500] loss: 131.929\n",
      "[4,  1000] loss: 132.926\n",
      "[5,   500] loss: 132.726\n",
      "[5,  1000] loss: 133.768\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define a Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        outputs = outputs.squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 500 == 499:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 500))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test data: 50 %\n"
     ]
    }
   ],
   "source": [
    "# test the network\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "test_dataLoader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_dataLoader:\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        outputs = outputs.squeeze()\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test data: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
